{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from src.tkns.tokenizer import RNASequenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data = False\n",
    "local_dir = \"./data\"\n",
    "\n",
    "if download_data:\n",
    "    dataset = load_dataset(\"multimolecule/rnacentral.1024\", cache_dir=local_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________\n",
    "## I. RNACentral data inspection and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_unique_nucleotides = False\n",
    "\n",
    "# Seearch unique nucleotides to build a vocabulary for the tokenizer.\n",
    "if search_unique_nucleotides:\n",
    "    chunk_size = 10_000\n",
    "    unique_nucleotides = set()\n",
    "\n",
    "    for chunk in pd.read_csv(f\"{local_dir}/rna_central.1024.csv\", chunksize=chunk_size):\n",
    "        sequences = chunk['sequence']\n",
    "\n",
    "        for seq in sequences:\n",
    "            unique_nucleotides.update(seq)\n",
    "        \n",
    "    unique_nucleotides = set([e.upper() for e in list(unique_nucleotides)])\n",
    "    print(\"Unique nucleotides:\", unique_nucleotides)\n",
    "\n",
    "    # Add special tokens to the vocabulary and populate the dictionary with unique nucleotides.\n",
    "    nucleotide2id = {'[PAD]': 0, '[MASK]': 1}\n",
    "\n",
    "    for i, w in enumerate(unique_nucleotides):\n",
    "        nucleotide2id[w] = i + len(nucleotide2id)\n",
    "\n",
    "    # Save vocabulary dict for tokenizer as json\n",
    "    json.dump(nucleotide2id, open(f\"{local_dir}/nucleotide2id.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [12, 12, 12, 2, 24, 30]\n",
      "Decoded: AAAFCG\n",
      "Encoding / decoding:  True\n"
     ]
    }
   ],
   "source": [
    "# Load and test tokenizer\n",
    "tokenizer = RNASequenceTokenizer()\n",
    "\n",
    "# Encoding and decoding example\n",
    "sequence = \"AAAFCG\" # sequences[0]\n",
    "encoded = tokenizer.encode(sequence)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "\n",
    "print(\"Encoded:\", encoded)\n",
    "print(\"Decoded:\", decoded)\n",
    "\n",
    "print(\"Encoding / decoding: \", sequence == decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________\n",
    "## II. Init dataset, collate function and dataloader. Inspect inputs, masked inputs and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from src.datasets.masked_lm import MLMDataset, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "        \"mask_prob\": 0.15\n",
    "    }\n",
    "sequences = [\"ACGTACGCGTAT\", \"TTGACAAAATTTGCGTA\", \"CGTACGTA\", \"ACGTACGT\", \"TTGACGTA\", \"CGTACGTA\"]\n",
    "\n",
    "tokenizer = RNASequenceTokenizer()\n",
    "dataset = MLMDataset(sequences, tokenizer, max_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader setup with partial function for collate_fn\n",
    "custom_collate_fn = partial(collate_fn,\n",
    "                            mask_token_id=tokenizer.vocabulary[\"[MASK]\"],\n",
    "                            mask_prob=config[\"mask_prob\"],\n",
    "                            pad_token_id=tokenizer.vocabulary[\"[PAD]\"])\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Input sequences:\n",
      "\tOriginal Sequence 1: 12 24 30 16 12 24 30 24 30 16\n",
      "\tMasked Sequence   1: 12 \u001b[31m1\u001b[0m 30 16 12 24 30 24 30 \u001b[31m1\u001b[0m\n",
      "\n",
      "Target sequences:\n",
      "\tSequence 1:      -100 24 -100 -100 -100 -100 -100 -100 -100 16\n",
      "\n",
      "\n",
      "Batch 2\n",
      "Input sequences:\n",
      "\tOriginal Sequence 1: 12 24 30 16 12 24 30 24 30 16\n",
      "\tMasked Sequence   1: 16 16 30 12 24 12 12 12 12 16\n",
      "\n",
      "Target sequences:\n",
      "\tSequence 1:      -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "\n",
      "\n",
      "Batch 3\n",
      "Input sequences:\n",
      "\tOriginal Sequence 1: 12 24 30 16 12 24 30 24 30 16\n",
      "\tMasked Sequence   1: 24 30 16 \u001b[31m1\u001b[0m 24 30 16 12 0 0\n",
      "\n",
      "Target sequences:\n",
      "\tSequence 1:      -100 -100 -100 12 -100 -100 -100 -100 -100 -100\n",
      "\n",
      "\n",
      "Batch 4\n",
      "Input sequences:\n",
      "\tOriginal Sequence 1: 12 24 30 16 12 24 30 24 30 16\n",
      "\tMasked Sequence   1: 12 24 \u001b[31m1\u001b[0m \u001b[31m1\u001b[0m 12 24 30 16 0 0\n",
      "\n",
      "Target sequences:\n",
      "\tSequence 1:      -100 -100 30 16 -100 -100 -100 -100 -100 -100\n",
      "\n",
      "\n",
      "Batch 5\n",
      "Input sequences:\n",
      "\tOriginal Sequence 1: 12 24 30 16 12 24 30 24 30 16\n",
      "\tMasked Sequence   1: 16 16 \u001b[31m1\u001b[0m 12 24 30 16 12 0 0\n",
      "\n",
      "Target sequences:\n",
      "\tSequence 1:      -100 -100 30 -100 -100 -100 -100 -100 -100 -100\n",
      "\n",
      "\n",
      "Batch 6\n",
      "Input sequences:\n",
      "\tOriginal Sequence 1: 12 24 30 16 12 24 30 24 30 16\n",
      "\tMasked Sequence   1: 24 \u001b[31m1\u001b[0m 16 12 24 30 16 12 0 0\n",
      "\n",
      "Target sequences:\n",
      "\tSequence 1:      -100 30 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a batch and demonstrate masking\n",
    "for batch_idx, (masked_input_ids, masked_labels) in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_idx + 1}\")\n",
    "    print(\"Input sequences:\")\n",
    "    \n",
    "    for seq_idx, (masked_sequence, pristine_sequence) in enumerate(zip(masked_input_ids, dataset)):\n",
    "        token_ids, _ = pristine_sequence\n",
    "        original_sequence = ' '.join(map(str, token_ids.tolist()))\n",
    "        masked_sequence_str = ' '.join(\n",
    "            f\"\\033[31m{token_id}\\033[0m\" if token_id == tokenizer.vocabulary.get(\"[MASK]\", 2) else str(token_id)\n",
    "            for token_id in masked_sequence.tolist()\n",
    "        )\n",
    "        print(f\"\\tOriginal Sequence {seq_idx + 1}: {original_sequence}\")\n",
    "        print(f\"\\tMasked Sequence   {seq_idx + 1}: {masked_sequence_str}\")\n",
    "    \n",
    "    print(\"\\nTarget sequences:\")\n",
    "    for seq_idx, sequence in enumerate(masked_labels):\n",
    "        print(f\"\\tSequence {seq_idx + 1}:      {' '.join(map(str, sequence.tolist()))}\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________________\n",
    "## Model initialization and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences:  32524827\n",
      "RNA types:  31\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(f\"{local_dir}/rna_central.1024.csv\")\n",
    "data.head(3)\n",
    "\n",
    "print(\"Number of sequences: \", len(data))\n",
    "print(\"RNA types: \", len(data.type.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = data.sequence.to_list()\n",
    "rna_types = data.type.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'dim': 256,\n",
    "    'n_heads': 8,\n",
    "    'attn_dropout': 0.1,\n",
    "    'mlp_dropout': 0.1,\n",
    "    'depth': 6,\n",
    "    'vocab_size': 8192,\n",
    "    'max_len': 128,\n",
    "    'pad_token_id': 1,\n",
    "    'mask_token_id': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.bert import BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT(config).to('cuda')\n",
    "print('trainable:', sum([p.numel() for p in model.parameters() if p.requires_grad]) / 1_000_000, 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLMRNACentral:\n",
    "    def __init__(self, sequences: List[str], tokenizer: Tokenizer):\n",
    "        self.sequences = sequences\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self,):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        seq = self.sequences[idx]\n",
    "        ids = self.tokenizer.encode(seq)\n",
    "        labels = ids.copy()\n",
    "        return ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [torch.tensor(i[0]) for i in batch]\n",
    "    labels = [torch.tensor(i[1]) for i in batch]\n",
    "\n",
    "    input_ids = torch.stack(input_ids)\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    # mask 15% of text leaving [PAD]\n",
    "    mlm_mask = torch.rand(input_ids.size()) < 0.15 * (input_ids!=1)\n",
    "    masked_tokens = input_ids * mlm_mask\n",
    "    labels[masked_tokens==0]=-100 # set all tokens except masked tokens to -100\n",
    "    input_ids[masked_tokens!=0]=2 # MASK TOKEN\n",
    "    return input_ids, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10 # including [mask] and [pad]\n",
    "max_len = 5\n",
    "num_seq = 5\n",
    "\n",
    "def gen_sample_data(vocab_size, max_len, num_seq):\n",
    "    \"\"\"generate a list of text with variable lengths\n",
    "    \"\"\"\n",
    "    # minus 2 for [0: padding ,1: mask]\n",
    "    gen_single_sequence = lambda : torch.randint(2, vocab_size-3, size=(torch.randint(1, max_len, size=(1,)),))\n",
    "    return [gen_single_sequence() for _ in range(num_seq)]\n",
    "\n",
    "seqs = gen_sample_data(vocab_size, max_len, num_seq)\n",
    "\n",
    "def batch_data(data):\n",
    "    \"\"\"Generate batched_data with padding\n",
    "    \"\"\"\n",
    "    num_samples = len(data)\n",
    "    full_data = torch.zeros(num_samples, max_len)\n",
    "    for i, sent in enumerate(data):\n",
    "        min_length = min(len(sent), max_len)\n",
    "        full_data[i, :min_length] = sent[:min_length]\n",
    "    return full_data.long()\n",
    "\n",
    "batch_data = batch_data(seqs)\n",
    "batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masking_prob = 0.15 \n",
    "full_mask = torch.randn(batch_data.shape) < masking_prob\n",
    "full_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
